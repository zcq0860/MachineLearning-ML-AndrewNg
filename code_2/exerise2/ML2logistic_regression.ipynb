{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编程作业2  logistic_regression（逻辑回归）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推荐运行环境：python 3.6  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight') #样式美化\n",
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "from sklearn.metrics import classification_report#这个包是评价报告"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ex2data1.txt', names=['exam1', 'exam2', 'admitted'])\n",
    "data.head()#看前五行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(context=\"notebook\", style=\"darkgrid\", palette=sns.color_palette(\"RdBu\", 2))\n",
    "\n",
    "sns.lmplot('exam1', 'exam2', hue='admitted', data=data, \n",
    "           size=6, \n",
    "           fit_reg=False, \n",
    "           scatter_kws={\"s\": 50}\n",
    "          )\n",
    "plt.show()#看下数据的样子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X(df):#读取特征\n",
    "#     \"\"\"\n",
    "#     use concat to add intersect feature to avoid side effect\n",
    "#     not efficient for big dataset though\n",
    "#     \"\"\"\n",
    "    ones = pd.DataFrame({'ones': np.ones(len(df))})#ones是m行1列的dataframe\n",
    "    data = pd.concat([ones, df], axis=1)  # 合并数据，根据列合并\n",
    "    return data.iloc[:, :-1].as_matrix()  # 这个操作返回 ndarray,不是矩阵\n",
    "\n",
    "\n",
    "def get_y(df):#读取标签\n",
    "#     '''assume the last column is the target'''\n",
    "    return np.array(df.iloc[:, -1])#df.iloc[:, -1]是指df的最后一列\n",
    "\n",
    "\n",
    "def normalize_feature(df):\n",
    "#     \"\"\"Applies function along input axis(default 0) of DataFrame.\"\"\"\n",
    "    return df.apply(lambda column: (column - column.mean()) / column.std())#特征缩放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_X(data)\n",
    "print(X.shape)\n",
    "\n",
    "y = get_y(data)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# sigmoid 函数\n",
    "g 代表一个常用的逻辑函数（logistic function）为S形函数（Sigmoid function），公式为： \\\\[g\\left( z \\right)=\\frac{1}{1+{{e}^{-z}}}\\\\] \n",
    "合起来，我们得到逻辑回归模型的假设函数： \n",
    "\t\\\\[{{h}_{\\theta }}\\left( x \\right)=\\frac{1}{1+{{e}^{-{{\\theta }^{T}}X}}}\\\\] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # your code here  (appro ~ 1 lines)\n",
    "    gz = None\n",
    "    return gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面程序会调用上面你写好的函数，并画出sigmoid函数图像。如果你的程序正确，你应该能在下方看到函数图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(np.arange(-10, 10, step=0.01),\n",
    "        sigmoid(np.arange(-10, 10, step=0.01)))\n",
    "ax.set_ylim((-0.1,1.1))\n",
    "ax.set_xlabel('z', fontsize=18)\n",
    "ax.set_ylabel('g(z)', fontsize=18)\n",
    "ax.set_title('sigmoid function', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cost function(代价函数)\n",
    "> * $max(\\ell(\\theta)) = min(-\\ell(\\theta))$  \n",
    "> * choose $-\\ell(\\theta)$ as the cost function\n",
    "\n",
    "$$\\begin{align}\n",
    "  & J\\left( \\theta  \\right)=-\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[{{y}^{(i)}}\\log \\left( {{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)+\\left( 1-{{y}^{(i)}} \\right)\\log \\left( 1-{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)]} \\\\ \n",
    " & =\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[-{{y}^{(i)}}\\log \\left( {{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)-\\left( 1-{{y}^{(i)}} \\right)\\log \\left( 1-{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)]} \\\\ \n",
    "\\end{align}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = theta=np.zeros(3) # X(m*n) so theta is n*1\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, X, y):\n",
    "    ''' cost fn is -l(theta) for you to minimize'''\n",
    "    # your code here  (appro ~ 2 lines)\n",
    "    costf = None\n",
    "    return costf\n",
    "# Hint:X @ theta与X.dot(theta)等价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cost(theta, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你写的代码正确，这里的输出应该是0.6931471805599453"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient descent(梯度下降)\n",
    "* 这是批量梯度下降（batch gradient descent）  \n",
    "* 转化为向量化计算： $\\frac{1}{m} X^T( Sigmoid(X\\theta) - y )$\n",
    "$$\\frac{\\partial J\\left( \\theta  \\right)}{\\partial {{\\theta }_{j}}}=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{({{h}_{\\theta }}\\left( {{x}^{(i)}} \\right)-{{y}^{(i)}})x_{_{j}}^{(i)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(theta, X, y):\n",
    "    # your code here  (appro ~ 2 lines)\n",
    "    \n",
    "    grad = None\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient(theta, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 拟合参数\n",
    "> * 这里我使用 [`scipy.optimize.minimize`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize) 去寻找参数  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = opt.minimize(fun=cost, x0=theta, args=(X, y), method='Newton-CG', jac=gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用训练集预测和验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, theta):\n",
    "    # your code here  (appro ~ 2 lines)\n",
    "    \n",
    "    y_pred = None\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_theta = res.x\n",
    "y_pred = predict(X, final_theta)\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 寻找决策边界\n",
    "http://stats.stackexchange.com/questions/93569/why-is-logistic-regression-a-linear-classifier\n",
    "> $X \\times \\theta = 0$  (this is the line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.x) # this is final theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = -(res.x / res.x[2])  # find the equation\n",
    "print(coef)\n",
    "\n",
    "x = np.arange(130, step=0.1)\n",
    "y = coef[0] + coef[1]*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()  # find the range of x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(context=\"notebook\", style=\"ticks\", font_scale=1.5)\n",
    "\n",
    "sns.lmplot('exam1', 'exam2', hue='admitted', data=data, \n",
    "           size=6, \n",
    "           fit_reg=False, \n",
    "           scatter_kws={\"s\": 25}\n",
    "          )\n",
    "\n",
    "plt.plot(x, y, 'grey')\n",
    "plt.xlim(0, 130)\n",
    "plt.ylim(0, 130)\n",
    "plt.title('Decision Boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3- 正则化逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ex2data2.txt', names=['test1', 'test2', 'accepted'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(context=\"notebook\", style=\"ticks\", font_scale=1.5)\n",
    "\n",
    "sns.lmplot('test1', 'test2', hue='accepted', data=df, \n",
    "           size=6, \n",
    "           fit_reg=False, \n",
    "           scatter_kws={\"s\": 50}\n",
    "          )\n",
    "\n",
    "plt.title('Regularized Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAD9CAYAAABncGgJAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsQAAA7EAZUrDhsAABnpSURBVHhe7d0JcNTUHwfwH6AIYhVQAfFCDlHwAjzQihcIOgMqKgqioqIilRkVEHQ80Onfo6CMoOAxgIIFxLtitfVCCwgeqCA6ciiWggc3IodWyT/f1xcItbubbPe1m+T7mdlp3kubJtvmty/vrGHZhIjIgJr6KxFRyjHAEJExDDBEZAwDDBEZwwBDRMawFYnS3gUXXKC39jRp0iRp2rSpTgVXv3795Pfff9ep3R555BFp166dTgUTSzCU9goLC6VevXpy3HHH7fGqXbu2/o5gO/roo/9zbbjm9evX6+8ILpZgKO3VqFFD3n333ZglmTDCNb///vvSpUsXnRNMLMEQkTEMMERxbNq0STZv3qxT5BcDDFE527Ztk7lz58q4cePkxBNPlFmzZuk95BcDDFE5JSUlsnjxYjn//PMrbN0h7xhgiMpp3bq1DBgwQLXuUOUwwBCRMQwwRGQMAwwRGcMAQ0TGMMAQkTEMMERkDAMMERnDAEMUQ2lpqfz777+yY8cOnUN+McAQlbNy5UoZPHiw9OzZU2rWrCkPPfSQZGVlSX5+vv4O8orTNVDa43QNwcUSDBEZwwBDRMYwwBCRMQwwRGQMAwwRGcMAQ0TGMMAQkTEMMERkDAMMERnDAENExjDAEJExDDBEZAwDDJHtr7/+ku3bt+uUyB9//CH//POPTlGyGGAo8qZNmyYzZsyQ7OxsmTJlikoXFhZKjx49pKioSH8XJYMBhiIN00Cccsopcu2118ott9wigwYNUvmXXHKJLFu2TE2bQMljgKG0N2bMGLXaogmYra5Vq1Zqe+nSpeprr169ZO+995bly5dLp06dVJ7bhg0b9JY5uGbnvIKMAYbS3m233SZLlizRqdTCrHWOzz//XM455xwVXCqSm5sro0aNkszMTJ1jDq4ZJaigY4Ah0j755BM599xzdeq/+vTpo16Yq5e8YYAhsqEVae7cuao+xoEpK91q1aqlt8grBhiKrHnz5kn79u3VygGvvvqqapZ26j1++ukn2blzp9qm5DHAUGRt3LhRDjroIJk1a5bstdde8uCDD8ozzzyjWpZQmunatav+TkoWVxWgtGdyVYE///xTPR4deOCBKo2gg0eh/fffX6XLW7VqlaoIRguTSVxVgCgE9ttvv13BBRo0aBAzuJB/DDBEHuXl5UlOTo6sWbNGRo4cKQsWLNB7KBY+IlHa48JrwcUSDBEZwwBDgRDFgnYYrpkBhgIBfVWiJgzXzABDgYB+KlEThmtmgCEiYxhgiMgYBhgiMoYBhoiMYYAhImMYYIjIGAYYIhuXLTGDAYYij8uWmMMAQ4Fgqtu832VLNm3aJKtXr66SbvwcKkBURUx1m/e6bAlu9rFjx0p+fr4UFBRI586dZcWKFWqfKRwqQFRFTHWb97psCfYVFxdL3759pX///tKhQwcZMmSI3msGhwoQhUi8ZUsw6537kaVNmzaybt06naJYGGCIbImWLWnZsqWMHj1ap0Q9KmGNJIqPAYYiK9llSyZNmiSNGjVSlcIUHwMMRVYyy5Zg39q1a2XcuHF8RPKAc/JS2kuXZUsQdLBsyZVXXql+7qmnnpK77rpL700tzslLFAJely3B4vvdunWT3r17q5s/IyNDSkpK9F6KhQGGyIPWrVurUgsK/M4Lj0kUHwMMERnDAEOBEMWqwjBcMwMMBQJXFQgmBhgKhHTpNl+Vgx05VIAoIhBQqnqwYxgwwBB5UB2DHcOAAYbIAw52TA4DDJEHHOyYHAYYIp842NE7BhgiHzjY0R8GGCKbl1UFMNgR+cOHD5etW7fKxIkT9R6KhQGGIs/LqgIc7JgcBhgKBFMd27yuKlAdgx1NXXNVYoChQKjuVQWqA4cKEFWR6l5VoDpwqABRiMRbVcBtw4YNeosSYYAhsiVaVQByc3Nl1KhRkpmZqXMoEQYYiiy/qwqg5y5epaWlOocSYYChyPK7qgAmAyd/uKoApb10WVUAsKoAKoLRwmQSVxUgCgGvqwpQchhgiMgYBhgiMoYBhgIhHaoK8/LyJCcnR9asWSMjR46UBQsW6D1mhKF6lJW8lPZQ4Tlz5kzp3r27zgk/kxXbVYklGAqEMHSb94tDBYiI4mCAISJjGGCIyBgGGCIyhgGGiIxhgCEiYxhgKBK8rBqQSCqOETXsaEdpr7KdzrBKAALBDz/8IMccc4zqX4JpMbGA2t133y1nnXWW/s7YUnEMPziamqgKJfs56HXVgHhScYxkhOGznwGGAiHZGfb9rhpQ0Xy7fo6xadMmWb16dUqCA1cVIKoiyXab97pqQLz5dr0cAwFl7NixalH8goIC6dy5s6xYsULvTQ6HChAFSLxVA7zOtxvrGAg8xcXF0rdvX+nfv7906NBBhgwZovdGFwMMRUKiVQO8zLcb7xiYFc/9WNSmTRsujm9jgKHQ8rtqQEW8HqNly5YyevRotQ14VEKJKOoYYCi0/K4aUJFkjoGm60aNGqkWp6hjPxhKe5XpB+Nn1YBYKwb4OQbOc9GiRTJs2DD1iHTwwQfrPf6wHwylNRTpX3rpJZ3ybsaMGaFoHnWkYtUAr8dAiQa9e4cPHy5bt26ViRMn6j3RFeoSDJ6Rx48fr1NlnKY/dxfvs88+W3r06KFT4TBixAhVB4Bep36gn8dzzz2nmmxNdSDzqzIlGK8w3+4HH3wgkydPlnvvvVc1M6MlyKslS5ao70dgcWRlZcm4ceN0yp+wlGBQ8x1qW7Zssa666ioEUevXX3/VuZa1bds267vvvrOuuOIK6+qrr9a5lVdSUmJt375dp6qH/Y9pPfvsszrlH3725Zdf1qnqh7+dHWB0Khpwzfg7Bl3oH5FQvHVq/Zs0aaK+Qt26dVVT4osvvig1a6bubXj77bdVb87qglaN++67T3VrT1a/fv1UCQb1DunC/l/VW9ERhmuOfB1M7dq1VaBJlY8//lhvVQ90BDvvvPOkTp06Ose/ffbZRz0iYCb/dBGmeiGvwnDNxgIM3hzUojtvEj7Vy/c7wLgPjPOoCKI36lB+/PHHCvsruI+P78W2n4iPkobjjDPO0FtlQ/AxYraiP26ic0I9wWuvvaZTe8L343r//vtvnVNxHn4v1t0B7Hc/0zvinePUqVNj9lYFlEq8TDmA1pRkKolNCUO3eb84VCCG2bNny5lnnqma6L755huxn+nVJ+utt94q//vf/9QNhMqvoqIiufnmm9ViVm4IFg888IC6kb///ntVAbtw4UK9t+xG7tixozo+htGPGTNGCgsL5YYbbpBHHnmkwpu/vA8//FBviRqstmXLFhkwYIDqTIXmSlSQuoNQonN6/fXX1c2NmxXXeNddd8mUKVPUPrQuoLIOLRH4WXDeI+ShWRNwXegl2rRpU/nyyy9VBTUqDnFtkOgcARWDp556qk7tCe8VWomys7PVuSGNY+Na8LdwO/300+XTTz/VKXKkcjBjJNhvlBH2Dakqqh599FGdY1n2p65Vs2ZNyw4IOseyli5datWqVctau3atzrGsO++80xo2bJhOWZZ981pt27a17MChcyzr559/VsefNGmSzrEs++a27E9e6/7779c5ZUaMGKG+d8iQIdYdd9xh9ezZ02rQoIHeW6ZXr17WY489plNl528HMMsOhirt5ZxQwYvf465MdhQXF6t9X3/9tc6xLPufVeV98cUXOseyli9frt6jF154QaXtoLZrf6JzxPU3btxYbZf3zjvvqPcacC4ZGRmWHRAtu/RktWjRwrIDjNrnVr9+fU8V1llZWdaVV17p6WV/oOzxnnmB96i6K3lxzvi/zc3NtSZMmGDZpUTLLs3qvamHaw5DJa+xAFNaWqrepLy8PJ1TdgMgz36M0DmWZRfzrRo1aljffvutzrGs6dOnW/fee69O7b45N27cqHMsFZCQt3LlSp1TBr+vdu3a1vr163XO7gADOIdly5ZZmZmZKg343djv3ICOk08+2Xr++efVtpdzihdg7EcTtc8dYAB57gDjXJdd6tE5Zbyc4y+//GK1bNlSbZeHgOjAPy4CDIJLPM2bN//P+1sRHAeByMsr0e+sCK67ugPM/PnzrcGDB+uUZQ0dOlR9UJmCa2YrkgeHH3643to9oMydhxYcvNwtFr179xa7xKAerfBCsR/Qo7K88n01TjzxRFWnYd/IOmdPOAeMG8FkQQ48jiDfvtFVvYPzwhgUtEKBn3OqiN+WqiOPPFJvlfFyjqjP2XfffdV2eV6nLXDDcfFYlgiOg0plL69EvzNd4VHWvl90ioMZPSuLM6nnlGASfWIDHpHcefn5+dbxxx9vzZ49W6VRIsDPoYTgcD7p3XngPDq5o7+7BOOwb0a9ZaliL0pR+ISNxcs5lS/B4HHHUdH7gWI38ioqwbgfGcHLOeL3NmvWTKdi69q1qzV69Gidis0OcuoxLJGFCxda8+bN8/Qq///gBd6P6i7BlHfZZZdZ48eP16nUwzWzBGMAWpWuuOIKefjhh1UlKGzbtk19hffee09vlbGvQW+VQYUpPiUT9cJEd2/Haaedpo5TfgwK8uyA5fmcnNKUc07uc0XpA/vd5+vnEzDROQIG5WGcTDwoKaLSOda0BW647oYNG+pUbKgMnjNnjqcXfrf7PQgiDmb0zliAwWOK+ytUlIcJfuxP8l3/dCjmo2n20EMPVWn49ttvVXEdNwe6srvh0cGBZtvHH39cdTRzBxDn97kfw9zwyIQWLoySdUMLy2+//eb5nNCRDx34fvnlF5V2NzMiuODnf//9d50jquUGj07upuiK3iNIdI6A34dzcJq5HXbJwfe0BThm/fr1//MIWhHcaEOHDvX0wjV4OWZVw9/RLh3qVOzme7T02aVL1QrKR6TEaj2AttcUwz80RpPi0xZjNOrVq6f+YKjDwCTJuCGRh/oL5CGNfh2oP0DzM4INmnxxA6OZGzcNXm+++aa0bt1aTjrpJFWCQG9TjCOyH01U0yGahzHlIX43blzcPPfcc49qQsY/z2effSZfffWV2I86kpGRoc+2DJqRsR+f5rgRMZ8Hzuf8889X3+vlnPA7EWDQO9ipb2jbtq3+DaKan6dPny6NGzdW9SC4gdFsjONh8Jz9iKOCI6ZaRBM4gpG7j068c3TgvcC5HnvssTqnLBiiZIcAhxupXbt2Mn/+fPWe4O+D+pnyNz1+B647HcbCYIqEq6++WgVZE9Bcj/cI/yf4P/ruu+/U3wD/R0ccccSu+jCUvhBc0FUAHwqoi3NKtKmGa0Zv7ObNm+ucgLL/GdMSWpdQh2EHJp1T1hLjcNfBoGUITYb4Wll2yUH93oqOleicHDg3d92MG8ZAobneaX2yb3DVzIw6Gq/inSNaOwYOHKhTu2FMlrs+BXVQmzdv1qn/sksllh2UdKp64e+MZnYTvDbf429mfyiqc3FeaJ43Bce3H7F1KrjSNsAk4g4wtBuCYKdOnfZoPvcLTfx2yUWnqh/+zjNnztSp1Eqm+b4q4JrTrWI7GWlXyeuVM2N7ZWduDxs8pqE3M2a4T9bTTz8tTz75pE6lB1Pd5pNpvq8qHCpQTVA/gOdm1N+88cYbquKNdkM9FCq5y3f/9wJDKFBH5HcemTCIt+qAg0MFfCoryFAYVdT9PxH7JtNb6QP/pqYfF3bs2KHqWJx+TuCuA+FQgeQE9hGJEiu/aqEXqV5jOZ35ab7nukfJYYChyEKnRK8rBnCoQHK4qgClPfTRwU1vYk5ePysGuF1++eVqUq6BAwfqnNTCNaOuMR36IVUGSzAUaeg46QQXiLVigBuHCnjHAEPkA0pSHCrgHQMMkUeol8GQF6575B0DDAVCdVcVYsxWt27d1LxAqB/BOC2M+zIpDNWjDDAUCGhKrk4Y0IoKYdz0zivZRdW8qu5rTgUGGAqEMHSb94tDBYgiBs3YmOArDKWLqsAAQ+TRE088oWbvwwBbzMGDehmKjwGGyANMH4rWI0wwhQGRzZo1k9zcXL2XYmGAIfIAMxRi6tQDDjhAVfBiBrwLL7xQ76VYGGCIPMI0r5jS4ZprrpGsrKw9pjOlijHAEPmAOaAnTJggL7/8sppPmeJjgCHyAI9HmHAd8LjkLMRH8THAENkSLVvy1ltvqRUfHFjVAqtCUHwMMBQIJrvNY/pVPO5kZ2fLlClTVBrrTfXo0WPXtKMXX3yxqnPB4nEfffSRWra3/BpVqWbymqsKAwwFgqmObRgdjVUusQYRpl8YNGiQysfa5VjDy1kvCtM4jBgxQn3FOKSCggLjlbwcKkBURUx1m0f/FmeaTGeFzl69eqmVBbBwoHvaUQQbLKSHgIQF9kzjUAGigEtm2RJU+JI3DDBEWqJlS9BzF8sVY1kY8oYBhsiGViRMKIXHHwfmxHXr06ePepWWluocSoQBhiLLz7IlgMnAyR8GGIosP8uWUHK4bAmlvXRatmTVqlWqIhgtTCZx2RKiEEhm2RLyjgGGiIxhgKFASIcn+by8PMnJyZE1a9bIyJEjZcGCBXqPGWGovWAdDKU91EfMnDlTunfvrnPCz2S9U1ViCYYCgasKBBMDDBEZwwBDRMYwwBCRMQwwRGQMAwwRGcMAQ0TGMMAQkTEMMERkDAMMBUIUO5yH4ZoZYCgQqmOGfUw6demll8qKFSt0TtXiqgJEVaQ6us2vX79ezXq3bt06nVO1OFSAKMQwP++vv/66xzy95A8DDBEZwwBDRMYwwBCRMQwwRGQMAwxRDNXdTB0GDDBEMVR3M3UYMMAQxcBm6spjgCEiY7iqAKW93377TerXry916tTROeEXlmtmCYbS3iGHHCIff/yxTkUDrnnOnDk6FVwMMEQxsBWp8hhgiGJgK1LlMcAQxcBWpMpjgCEiYxhgiMgYBhgiMoYBhoiMYYAhImMYYIhSZPPmzbJz5061/ddff8nWrVvVdpQxwFAgBGFEy3XXXScNGjSQNm3aSNeuXVWQqQwuW0JURYKwhMdZZ50l77//vrzyyitqaEPDhg31nuRw2RKiKhKEJTzq1q0r7dq1k4MPPlhq1Kihc5PHZUuIaJcff/xRJk+eLPPnz5d+/fqpXsBRxwBDlCIPPvig3HjjjXLRRRep4QX33Xef3hNdDDBEKVBSUqJKL45mzZrJggULdCq6GGAoEtCis337dp0S+eOPP+Sff/7RKW/iHQNTO6xcuVJtAwIO6mOijjPaUdpDhem7774rF1xwgc7xZ9q0aSoQ/PDDD3LMMceoytO9995bJk2aJHfffbdq/Ukk0THOPPNMycnJkVNPPVWd7/jx42XcuHHSuHFjfQR/cAy0SHXp0kXnBBQCDFE6w7+pHWB0yp933nnHWrp0qdouLi62MjIyrKlTp1p///231aJFC6uoqEjti8frMXbu3GktXrzYWrRokWUHI5WXLFyzHWB0Krj4iEShtmPHDmnVqpXatoOE+tqrVy9V+li+fLl06tRJ5Tk2bNigt3bzegyUOtq2bSvHH3+81KpVS+VFHQMMhVrPnj31lsjnn38u55xzjgoM5eXm5sqoUaMkMzNT5+zm9RiwadMmWb16dSh64aYCAwwFglNyqIxPPvlEzj33XJ3aU58+fdSrtLRU51Qs1jEQUMaOHSv5+flSUFAgnTt3rvRcvsuWLdNbwcUAQ4HQvHlzvZUctADNnTt3j+kvUYnq8PJIE+8YKNkUFxdL3759pX///tKhQwcZMmSI2peso446Sm8FFwMMBUIy3eYxYXf79u3VmJ5XX31VtQI5dSloVnZGPsfj9RgHHnjgHo9FGPBY2cnCOVSAKI1t3LhRDjroIJk1a5a6WdHT9plnnlFN3iiJYMRzIl6P0bJlSxk9erTaBjwq4ZEr6tgPhtJeZfrB/Pnnn+rRBiUMQMDA49D++++v0m6rVq1SFbhoGXLzcwxA35gvv/xS9YPBuScjLP1gWIKhUNtvv/12BQbAfC2xAkMsfo6BQLh27VoVXLieEgMMkZKXl6d64q5Zs0ZGjhyZ1DgiPDJh+MDw4cPVbHYTJ07Ue6KLj0iU9irziFRVlixZolqO3NNkZmVlqZJMMviIRES7tG7dWtXV4PPaeSUbXMKEAYaIjGGAISJjGGCIfEIzNZck8YYBhsgjBBa0EM2ePVveeOMN1fJE8THAEHl0/fXXq7WPMOcu+sGgSZviY4Ah8mDx4sVq1QAMCcB2t27d5KabbtJ7KRYGGCIPFi5cqOaAmT59uhrwOGDAABVoKD4GGCIPtmzZouZ3ueqqq+Skk05SX2+77Ta9l2JhgCGyxVsxALAMCabCdKZQwNikRYsWqW2KjQGGIg8rBsyYMUOys7NlypQpKl1YWCg9evSQoqIi9T2YZAqtSM7IGgxkPOGEE9Q2xcYAQ5GGMU4IHtdee63ccsstMmjQIJV/ySWXqCkrnekWUGK5/fbb5fHHH5dvvvlGBaInn3xS7aPYGGAo0vysOoCpMDGJFH5mwoQJatY6io8BhiLNz4oBcOihh0rHjh2lbt26OofiYYAh0uKtOuDgsiT+MMAQ2RKtOoCAkuplSaKAAYYiy8+qAyaWJYkCBhiKLDQ7e111AK1I7seiVCxLEgWcMpPSnskpM/2uGOC4/PLL1WPSwIEDdU5qccpMohBIZtUBLEvSqFEj1W+G4mOAIfKBy5L4wwBD5BGXJfGPAYbIAyxLgjlgevfurepHMjIypKSkRO+lWBhgiDzgsiTJYSsSpT2UGJo0aSL16tXTOWU+/PBDOfLII3UquM4++2zVO9gNs+eFoRWJAYbSHvqmVAQDDw844ACdCq6pU6eqCa3K6969uxx22GE6FUwMMERkDOtgiMgYBhgiMoYBhoiMYYAhImMYYIjIGAYYIjKGAYaIjGGAISJjGGCIyBgGGCIyhgGGiIxhgCEiYxhgiMgQkf8DZ8ifzERedBgAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature mapping（特征映射）\n",
    "\n",
    "polynomial expansion\n",
    "\n",
    "```\n",
    "for i in 0..i\n",
    "  for p in 0..i:\n",
    "    output x^(i-p) * y^p\n",
    "```![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_mapping(x, y, power, as_ndarray=False):\n",
    "#     \"\"\"return mapped features as ndarray or dataframe\"\"\"\n",
    "\n",
    "    data = {\"f{}{}\".format(i - p, p): np.power(x, i - p) * np.power(y, p)\n",
    "                for i in np.arange(power + 1)\n",
    "                for p in np.arange(i + 1)\n",
    "            }\n",
    "\n",
    "    if as_ndarray:\n",
    "        return pd.DataFrame(data).as_matrix()\n",
    "    else:\n",
    "        return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array(df.test1)\n",
    "x2 = np.array(df.test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = feature_mapping(x1, x2, power=6)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regularized cost（正则化代价函数）\n",
    "$$J\\left( \\theta  \\right)=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[-{{y}^{(i)}}\\log \\left( {{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)-\\left( 1-{{y}^{(i)}} \\right)\\log \\left( 1-{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)]}+\\frac{\\lambda }{2m}\\sum\\limits_{j=1}^{n}{\\theta _{j}^{2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros(data.shape[1])\n",
    "X = feature_mapping(x1, x2, power=6, as_ndarray=True)\n",
    "print(X.shape)\n",
    "\n",
    "y = get_y(df)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_cost(theta, X, y, l=1):\n",
    "    # your code here  (appro ~ 3 lines\n",
    "    \n",
    "    \n",
    "    regu_cost = None\n",
    "    return regu_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularized_cost(theta, X, y, l=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为我们设置theta为0，所以这个正则化代价函数与代价函数的值应该相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regularized gradient(正则化梯度)\n",
    "$$\\frac{\\partial J\\left( \\theta  \\right)}{\\partial {{\\theta }_{j}}}=\\left( \\frac{1}{m}\\sum\\limits_{i=1}^{m}{\\left( {{h}_{\\theta }}\\left( {{x}^{\\left( i \\right)}} \\right)-{{y}^{\\left( i \\right)}} \\right)} \\right)+\\frac{\\lambda }{m}{{\\theta }_{j}}\\text{ }\\text{             for  j}\\ge \\text{1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_gradient(theta, X, y, l=1):\n",
    "    # your code here  (appro ~ 3 lines)\n",
    "    \n",
    "    \n",
    "    regularized_term = None\n",
    "    return gradient(theta, X, y) + regularized_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularized_gradient(theta, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拟合参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('init cost = {}'.format(regularized_cost(theta, X, y)))\n",
    "\n",
    "res = opt.minimize(fun=regularized_cost, x0=theta, args=(X, y), method='Newton-CG', jac=regularized_gradient)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_theta = res.x\n",
    "y_pred = predict(X, final_theta)\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用不同的 $\\lambda$ （这个是常数）\n",
    "# 画出决策边界\n",
    "* 我们找到所有满足 $X\\times \\theta = 0$ 的x\n",
    "* instead of solving polynomial equation, just create a coridate x,y grid that is dense enough, and find all those $X\\times \\theta$ that is close enough to 0, then plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boundary(power, l):\n",
    "#     \"\"\"\n",
    "#     power: polynomial power for mapped feature\n",
    "#     l: lambda constant\n",
    "#     \"\"\"\n",
    "    density = 1000\n",
    "    threshhold = 2 * 10**-3\n",
    "\n",
    "    final_theta = feature_mapped_logistic_regression(power, l)\n",
    "    x, y = find_decision_boundary(density, power, final_theta, threshhold)\n",
    "\n",
    "    df = pd.read_csv('ex2data2.txt', names=['test1', 'test2', 'accepted'])\n",
    "    sns.lmplot('test1', 'test2', hue='accepted', data=df, size=6, fit_reg=False, scatter_kws={\"s\": 100})\n",
    "\n",
    "    plt.scatter(x, y, c='R', s=10)\n",
    "    plt.title('Decision boundary')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_mapped_logistic_regression(power, l):\n",
    "#     \"\"\"for drawing purpose only.. not a well generealize logistic regression\n",
    "#     power: int\n",
    "#         raise x1, x2 to polynomial power\n",
    "#     l: int\n",
    "#         lambda constant for regularization term\n",
    "#     \"\"\"\n",
    "    df = pd.read_csv('ex2data2.txt', names=['test1', 'test2', 'accepted'])\n",
    "    x1 = np.array(df.test1)\n",
    "    x2 = np.array(df.test2)\n",
    "    y = get_y(df)\n",
    "\n",
    "    X = feature_mapping(x1, x2, power, as_ndarray=True)\n",
    "    theta = np.zeros(X.shape[1])\n",
    "\n",
    "    res = opt.minimize(fun=regularized_cost,\n",
    "                       x0=theta,\n",
    "                       args=(X, y, l),\n",
    "                       method='TNC',\n",
    "                       jac=regularized_gradient)\n",
    "    final_theta = res.x\n",
    "\n",
    "    return final_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_decision_boundary(density, power, theta, threshhold):\n",
    "    t1 = np.linspace(-1, 1.5, density)\n",
    "    t2 = np.linspace(-1, 1.5, density)\n",
    "\n",
    "    cordinates = [(x, y) for x in t1 for y in t2]\n",
    "    x_cord, y_cord = zip(*cordinates)\n",
    "    mapped_cord = feature_mapping(x_cord, y_cord, power)  # this is a dataframe\n",
    "\n",
    "    inner_product = mapped_cord.as_matrix() @ theta\n",
    "\n",
    "    decision = mapped_cord[np.abs(inner_product) < threshhold]\n",
    "\n",
    "    return decision.f10, decision.f01\n",
    "#寻找决策边界函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 改变$\\lambda$的值，查看效果（选做）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_boundary(power=6, l=1)     #set lambda = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_boundary(power=6, l=None)  # set lambda < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_boundary(power=6, l=100)  # set lambda > 10"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
